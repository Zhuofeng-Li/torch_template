{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# checkList for Model\n",
    "## network alg\n",
    "+ network init?\n",
    "## loss\n",
    "+ loss input, target, output? nn.CrossEntropyLoss, (N, C), (N), (N)\n",
    "## optimizer\n",
    "+ what optimizer? Adam\n",
    "## training_step\n",
    "+ forward and loss?\n",
    "+ log?\n",
    "+ return loss(must included, maybe state)?\n",
    "## validation_step\n",
    "+ inference and loss?\n",
    "+ choose metrics ?\n",
    "+ log?\n",
    "## test_step\n",
    "+ any special?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# python\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "\n",
    "# random\n",
    "import random\n",
    "#data analysis libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning\n",
    "import sklearn\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "#d2l\n",
    "import d2l.torch as d2l\n",
    "\n",
    "# For plotting learning curve\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# For Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# auto load change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-10T08:29:49.946603100Z",
     "start_time": "2023-08-10T08:29:19.933380Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# pl model API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "+ train_step\n",
    "+ log: step log and epoch log\n",
    "+ every train_epoch_end"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "\n",
    "        # logs metrics for each training_step,\n",
    "        # and the average across the epoch, to the progress bar and logger\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss  # must return loss(including dict form)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        all_preds = torch.stack(self.training_step_outputs)\n",
    "        # do something with all preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-10T08:29:50.657488200Z",
     "start_time": "2023-08-10T08:29:49.956605100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # You can add metrics to measure\n",
    "        self.log('loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "\n",
    "def on_validation_epoch_end(self):\n",
    "    all_preds = torch.stack(self.validation_step_outputs)\n",
    "    # do something with all preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**It is very useful to use `validate` to check benchmark(in only one epoch)**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LitModel()\n",
    "trainer = pl.Trainer()\n",
    "trainer.validate(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)  # You can add metrics to measure\n",
    "        self.log('loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # often reuse validation_step\n",
    "        self.validation_step(batch, batch_idx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# call after training\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model)\n",
    "\n",
    "# automatically auto-loads the best weights from the previous run\n",
    "trainer.test(dataloaders=test_dataloader)\n",
    "\n",
    "# or call with pretrained model\n",
    "model = MyLightningModule.load_from_checkpoint(PATH)\n",
    "trainer = Trainer()\n",
    "trainer.test(model, dataloaders=test_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## predict\n",
    "+ predict calls `forward` by default"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LitMCdropoutModel(pl.LightningModule):\n",
    "    def __init__(self, model, mc_iteration):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.mc_iteration = mc_iteration\n",
    "\n",
    "    # call forward by default\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # enable Monte Carlo Dropout\n",
    "        self.dropout.train()\n",
    "\n",
    "        # take average of `self.mc_iteration` iterations\n",
    "        pred = torch.vstack([self.dropout(self.model(x)).unsqueeze(0) for _ in range(self.mc_iteration)]).mean(dim=0)\n",
    "        return pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# call after training\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mTrainer\u001B[49m()\n\u001B[0;32m      3\u001B[0m trainer\u001B[38;5;241m.\u001B[39mfit(model)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# automatically auto-loads the best weights from the previous run\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# call after training\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model)\n",
    "\n",
    "# automatically auto-loads the best weights from the previous run\n",
    "predictions = trainer.predict(dataloaders=predict_dataloader)\n",
    "\n",
    "# or call with pretrained model\n",
    "model = MyLightningModule.load_from_checkpoint(PATH)\n",
    "trainer = Trainer()\n",
    "predictions = trainer.predict(model, dataloaders=test_dataloader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-10T08:53:40.655501500Z",
     "start_time": "2023-08-10T08:53:40.395139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use model after training or load weights and drop into the production system\n",
    "model = ClassificationTask.load_from_checkpoint(\"best_model.ckpt\")\n",
    "x = ...\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = model(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## save Hyperparameters\n",
    "+ use `self.params`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LitMNIST(pl.LightningModule):\n",
    "    def __init__(self, layer_1_dim=128, learning_rate=1e-2):\n",
    "        super().__init__()\n",
    "        # call this to save (layer_1_dim=128, learning_rate=1e-4) to the checkpoint\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # equivalent\n",
    "        self.save_hyperparameters(\"layer_1_dim\", \"learning_rate\")\n",
    "\n",
    "        # ignore the layer_1_dim\n",
    "        self.save_hyperparameters(ignore=[\"layer_1_dim\"])\n",
    "\n",
    "\n",
    "        # Now possible to access layer_1_dim from hparams\n",
    "        self.hparams.layer_1_dim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load_from_checkpoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the excluded parameters were `loss_fx` and `generator_network`\n",
    "model = LitMNIST.load_from_checkpoint(PATH, loss_fx=torch.nn.SomeOtherLoss, generator_network=MyGenerator())"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
